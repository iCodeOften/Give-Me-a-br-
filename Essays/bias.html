<!DOCTYPE html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, fit-to-shrink=no">
  <link href="https://fonts.googleapis.com/css?family=Pacifico" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Abril+Fatface|Open+Sans:700i" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="../articles1.css">
  <title>Articles</title>
</head>

<body>
  <div class="custom-padding">
    <nav>
      <div class="logo">Logo</div>
      <ul class="menu-area">
        <li><a href="#">Home</a></li>
         <li><a href="#">Biography</a></li>
         <li><a href="#">FAQ</a></li>
         <li><a href="#">Link</a></li>
         <li><a href="#">Readings</a></li>
      </ul>
    </nav>
  </div>

  <div class="body_text">
    <h1>A Way to Detect Bias</h1> <br>
    October 2015<br><br>This will come as a surprise to a lot of people, but in some cases
    it's possible to detect bias in a selection process without knowing
    anything about the applicant pool.  Which is exciting because among
    other things it means third parties can use this technique to detect
    bias whether those doing the selecting want them to or not.<br><br>You can use this technique whenever (a) you have at least
    a random sample of the applicants that were selected, (b) their
    subsequent performance is measured, and (c) the groups of
    applicants you're comparing have roughly equal distribution of ability.<br><br>How does it work?  Think about what it means to be biased.  What
    it means for a selection process to be biased against applicants
    of type x is that it's harder for them to make it through.  Which
    means applicants of type x have to be better to get selected than
    applicants not of type x.
    <font color=#999999>[<a href="#f1n"><font color=#999999>1</font></a>]</font>
    Which means applicants of type x
    who do make it through the selection process will outperform other
    successful applicants.  And if the performance of all the successful
    applicants is measured, you'll know if they do.<br><br>Of course, the test you use to measure performance must be a valid
    one.  And in particular it must not be invalidated by the bias you're
    trying to measure.
    But there are some domains where performance can be measured, and
    in those detecting bias is straightforward. Want to know if the
    selection process was biased against some type of applicant?  Check
    whether they outperform the others.  This is not just a heuristic
    for detecting bias.  It's what bias means.<br><br>For example, many suspect that venture capital firms are biased
    against female founders. This would be easy to detect: among their
    portfolio companies, do startups with female founders outperform
    those without?  A couple months ago, one VC firm (almost certainly
    unintentionally) published a study showing bias of this type. First
    Round Capital found that among its portfolio companies, startups
    with female founders <a href="http://10years.firstround.com/#one"><u>outperformed</u></a>
    those without by 63%.
    <font color=#999999>[<a href="#f2n"><font color=#999999>2</font></a>]</font><br><br>The reason I began by saying that this technique would come as a
    surprise to many people is that we so rarely see analyses of this
    type.  I'm sure it will come as a surprise to First Round that they
    performed one. I doubt anyone there realized that by limiting their
    sample to their own portfolio, they were producing a study not of
    startup trends but of their own biases when selecting companies.<br><br>I predict we'll see this technique used more in the future.  The
    information needed to conduct such studies is increasingly available.
    Data about who applies for things is usually closely guarded by the
    organizations selecting them, but nowadays data about who gets
    selected is often publicly available to anyone who takes the trouble
    to aggregate it.<br><br><br><br><br><br><br><br>
    <b>Notes</b><br><br>[<a name="f1n"><font color=#000000>1</font></a>]
    This technique wouldn't work if the selection process looked
    for different things from different types of applicants&mdash;for
    example, if an employer hired men based on their ability but women
    based on their appearance.<br><br>[<a name="f2n"><font color=#000000>2</font></a>]
    As Paul Buchheit points out, First Round excluded their most
    successful investment, Uber, from the study.  And while it
    makes sense to exclude outliers from some types of studies,
    studies of returns from startup investing, which is all about
    hitting outliers, are not one of them.<br><br>
    <b>Thanks</b> to Sam Altman, Jessica Livingston, and Geoff Ralston for reading
    drafts of this.
  </div>
  <br>
  <div float="left">
    <a href="../articles.html"><<u>Back</u></a>
</body>
<footer class="fixed-footer">
    <div>
        <ul>
          <li>Links: </li>
          <li class="right"><a href = "mailto: paulgram@edu.edu"><i>Paulgraham@edu.edu</i></li>
          <div class="inline-block">
            <li> <a href="https://www.ycombinator.com/"> <img src="../Y.png" alt = "icon_1" style= "height: 40px; width: 40px; border: 0px; padding: 2px"> </a></li>
          </div>
          <div class="inline-block">
            <li> <a href="https://twitter.com/paulg"> <img src="../twitter.png" alt = "icon_2" style= "height: 40px; width: 40px; border: 0px; padding: 2px"> </a></li>
          </div>
          <div class="inline-block">
            <li> <a href="https://www.amazon.com/gp/product/0596006624"> <img src="../H&P.png" alt = "icon_3" style= "height: 40px; width: 40px; border: 0px; padding: 2px"> </a></li>
          </div>
        </ul>
    </div>
</footer>
</body>
</html>
